{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Los Santos locals obituaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "_00 Exploration_ is the rough draft where we generated the texts for [@evryCalifornian](twitter.com/evhttp://localhost:8888/notebooks/obituary-generation.ipynb#Cleaning-up-00-Exploration.ipynbryCalifornian)\n",
    "\n",
    "In this notebook, we will condense and clean that process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Set up__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data analysis\n",
    "import gzip         # to work with zip files \n",
    "import spacy        # for NLP (dealing with occupations)\n",
    "\n",
    "# this changes the settings in your Jupyter Notebook so it displays multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376035, 136)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>datanum</th>\n",
       "      <th>serial</th>\n",
       "      <th>hhwt</th>\n",
       "      <th>statefip</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>city</th>\n",
       "      <th>puma</th>\n",
       "      <th>homeland</th>\n",
       "      <th>gq</th>\n",
       "      <th>...</th>\n",
       "      <th>vetwwii</th>\n",
       "      <th>vetother</th>\n",
       "      <th>pwstate2</th>\n",
       "      <th>pwpuma00</th>\n",
       "      <th>tranwork</th>\n",
       "      <th>carpool</th>\n",
       "      <th>riders</th>\n",
       "      <th>trantime</th>\n",
       "      <th>departs</th>\n",
       "      <th>arrives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>102</td>\n",
       "      <td>california</td>\n",
       "      <td>107</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>10702</td>\n",
       "      <td>puma does not include a homeland area</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a; n/a or no (1980, 1990 us)</td>\n",
       "      <td>n/a (all years) or no</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>102</td>\n",
       "      <td>california</td>\n",
       "      <td>107</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>10702</td>\n",
       "      <td>puma does not include a homeland area</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>122</td>\n",
       "      <td>california</td>\n",
       "      <td>65</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>6514</td>\n",
       "      <td>puma does not include a homeland area</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a; n/a or no (1980, 1990 us)</td>\n",
       "      <td>n/a (all years) or no</td>\n",
       "      <td>california</td>\n",
       "      <td>7100</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>22</td>\n",
       "      <td>1105</td>\n",
       "      <td>1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>122</td>\n",
       "      <td>california</td>\n",
       "      <td>65</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>6514</td>\n",
       "      <td>puma does not include a homeland area</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a; n/a or no (1980, 1990 us)</td>\n",
       "      <td>n/a (all years) or no</td>\n",
       "      <td>california</td>\n",
       "      <td>3700</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>141</td>\n",
       "      <td>502</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>122</td>\n",
       "      <td>california</td>\n",
       "      <td>65</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>6514</td>\n",
       "      <td>puma does not include a homeland area</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a; n/a or no (1980, 1990 us)</td>\n",
       "      <td>n/a (all years) or no</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  datanum  serial  hhwt    statefip  countyfips  \\\n",
       "0  2016        1   67752   102  california         107   \n",
       "1  2016        1   67752   102  california         107   \n",
       "2  2016        1   67753   122  california          65   \n",
       "3  2016        1   67753   122  california          65   \n",
       "4  2016        1   67753   122  california          65   \n",
       "\n",
       "                                       city   puma  \\\n",
       "0  not in identifiable city (or size group)  10702   \n",
       "1  not in identifiable city (or size group)  10702   \n",
       "2  not in identifiable city (or size group)   6514   \n",
       "3  not in identifiable city (or size group)   6514   \n",
       "4  not in identifiable city (or size group)   6514   \n",
       "\n",
       "                                homeland                                gq  \\\n",
       "0  puma does not include a homeland area  households under 1970 definition   \n",
       "1  puma does not include a homeland area  households under 1970 definition   \n",
       "2  puma does not include a homeland area  households under 1970 definition   \n",
       "3  puma does not include a homeland area  households under 1970 definition   \n",
       "4  puma does not include a homeland area  households under 1970 definition   \n",
       "\n",
       "    ...                            vetwwii               vetother    pwstate2  \\\n",
       "0   ...     n/a; n/a or no (1980, 1990 us)  n/a (all years) or no         n/a   \n",
       "1   ...                                 no                     no         n/a   \n",
       "2   ...     n/a; n/a or no (1980, 1990 us)  n/a (all years) or no  california   \n",
       "3   ...     n/a; n/a or no (1980, 1990 us)  n/a (all years) or no  california   \n",
       "4   ...     n/a; n/a or no (1980, 1990 us)  n/a (all years) or no         n/a   \n",
       "\n",
       "  pwpuma00             tranwork       carpool        riders  trantime departs  \\\n",
       "0        0                  n/a           n/a           n/a         0       0   \n",
       "1        0                  n/a           n/a           n/a         0       0   \n",
       "2     7100  auto, truck, or van  drives alone  drives alone        22    1105   \n",
       "3     3700  auto, truck, or van  drives alone  drives alone       141     502   \n",
       "4        0                  n/a           n/a           n/a         0       0   \n",
       "\n",
       "   arrives  \n",
       "0        0  \n",
       "1        0  \n",
       "2     1124  \n",
       "3      704  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'datanum', 'serial', 'hhwt', 'statefip', 'countyfips', 'city', 'puma', 'homeland', 'gq', 'gqtype', 'gqtyped', 'farm', 'ownershp', 'ownershpd', 'mortgage', 'mortgag2', 'farmprod', 'acrehous', 'mortamt1', 'mortamt2', 'rent', 'rentgrs', 'rentmeal', 'costelec', 'costgas', 'costwatr', 'costfuel', 'foodstmp', 'lingisol', 'fridge', 'hotwater', 'bedrooms', 'phone', 'cinethh', 'cilaptop', 'cismrtphn', 'citablet', 'ciothcomp', 'cidatapln', 'fuelheat', 'vehicles', 'ssmc', 'nfams', 'nsubfam', 'ncouples', 'multgen', 'multgend', 'pernum', 'perwt', 'sex', 'age', 'marst', 'birthyr', 'marrno', 'yrmarr', 'divinyr', 'widinyr', 'race', 'raced', 'hispan', 'hispand', 'bpl', 'bpld', 'ancestr1', 'ancestr1d', 'ancestr2', 'ancestr2d', 'citizen', 'yrnatur', 'yrimmig', 'yrsusa1', 'language', 'languaged', 'hcovany', 'hinsemp', 'hinscaid', 'hinscare', 'hinsva', 'hinsihs', 'educ', 'educd', 'gradeatt', 'gradeattd', 'schltype', 'degfield', 'degfieldd', 'degfield2', 'degfield2d', 'empstat', 'empstatd', 'labforce', 'occ', 'ind', 'classwkr', 'classwkrd', 'wkswork2', 'uhrswork', 'looking', 'availble', 'inctot', 'ftotinc', 'incwage', 'incbus00', 'incss', 'incwelfr', 'incinvst', 'incretir', 'incsupp', 'incother', 'incearn', 'poverty', 'migrate1', 'migrate1d', 'migplac1', 'migpuma1', 'movedin', 'vetstat', 'vetstatd', 'vet01ltr', 'vet90x01', 'vet75x90', 'vetvietn', 'vet55x64', 'vetkorea', 'vet47x50', 'vetwwii', 'vetother', 'pwstate2', 'pwpuma00', 'tranwork', 'carpool', 'riders', 'trantime', 'departs', 'arrives']\n"
     ]
    }
   ],
   "source": [
    "# to keep datafiles small work with the gzip file\n",
    "with gzip.open(\"../data/raw/usa_00035.dta.gz\", \"rb\") as file:\n",
    "    df = pd.read_stata(file)\n",
    "    \n",
    "df.shape\n",
    "df.head().get()\n",
    "\n",
    "# there are 137 columns so it's better to print them out this way\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Cleaning up__\n",
    "\n",
    "We need to deal with `\"countyfips\"` and `\"occ\"` codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `\"countyfips\"` we have the csv file `county_fips.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kings</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Placer</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sierra</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county  fips\n",
       "0  Alameda     1\n",
       "1    Kings    31\n",
       "2   Placer    61\n",
       "3   Sierra    91\n",
       "4   Alpine     3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_fips = pd.read_csv(\"../data/raw/county_fips.csv\")\n",
    "\n",
    "county_fips['fips'] = county_fips['fips'].astype(int) # to match df's\n",
    "\n",
    "county_fips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_codes = county_fips[['fips', 'county']].to_dict(orient = 'records')\n",
    "\n",
    "ls_codes_fips = []\n",
    "\n",
    "for code in fips_codes:\n",
    "    ls_codes_fips.append(list(code.values()))\n",
    "    \n",
    "    fips = {item[0]: item[1] for item in ls_codes_fips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Alameda',\n",
       " 31: 'Kings',\n",
       " 61: 'Placer',\n",
       " 91: 'Sierra',\n",
       " 3: 'Alpine',\n",
       " 33: 'Lake',\n",
       " 63: 'Plumas',\n",
       " 93: 'Siskiyou',\n",
       " 5: 'Amador',\n",
       " 35: 'Lassen',\n",
       " 65: 'Riverside',\n",
       " 95: 'Solano',\n",
       " 7: 'Butte',\n",
       " 37: 'Los Angeles',\n",
       " 67: 'Sacramento',\n",
       " 97: 'Sonoma',\n",
       " 9: 'Calaveras',\n",
       " 39: 'Madera',\n",
       " 69: 'San Benito',\n",
       " 99: 'Stanislaus',\n",
       " 11: 'Colusa',\n",
       " 41: 'Marin',\n",
       " 71: 'San Bernardino',\n",
       " 101: 'Sutter',\n",
       " 13: 'Contra Costa',\n",
       " 43: 'Mariposa',\n",
       " 73: 'San Diego',\n",
       " 103: 'Tehama',\n",
       " 15: 'Del Norte',\n",
       " 45: 'Mendocino',\n",
       " 75: 'San Francisco',\n",
       " 105: 'Trinity',\n",
       " 17: 'El Dorado',\n",
       " 47: 'Merced',\n",
       " 77: 'San Joaquin',\n",
       " 107: 'Tulare',\n",
       " 19: 'Fresno',\n",
       " 49: 'Modoc',\n",
       " 79: 'San Luis Obispo',\n",
       " 109: 'Tuolumne',\n",
       " 21: 'Glenn',\n",
       " 51: 'Mono',\n",
       " 81: 'San Mateo',\n",
       " 111: 'Ventura',\n",
       " 23: 'Humboldt',\n",
       " 53: 'Monterey',\n",
       " 83: 'Santa Barbara',\n",
       " 113: 'Yolo',\n",
       " 25: 'Imperial',\n",
       " 55: 'Napa',\n",
       " 85: 'Santa Clara',\n",
       " 115: 'Yuba',\n",
       " 27: 'Inyo',\n",
       " 57: 'Nevada',\n",
       " 87: 'Santa Cruz',\n",
       " 29: 'Kern',\n",
       " 59: 'Orange',\n",
       " 89: 'Shasta'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can `map` those values to `df['countyfips']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countyfips'] = df['countyfips'].map(fips)\n",
    "\n",
    "# fill null values with a string value so you can manipulate the series more easily later on\n",
    "df['countyfips'] = df['countyfips'].fillna(value = 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This same process we will repeat with `df['occ']`\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACS</th>\n",
       "      <th>Occupation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A (Less than 16 years old/unemployed who nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Chief executivesand legislators2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>General and operations managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Advertising and promotions managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Marketing and sales managers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACS                                    Occupation Name\n",
       "0    0  N/A (Less than 16 years old/unemployed who nev...\n",
       "1   10                   Chief executivesand legislators2\n",
       "2   20                    General and operations managers\n",
       "3   40                Advertising and promotions managers\n",
       "4   50                       Marketing and sales managers"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ = pd.read_csv(\"../data/raw/OCC2016.csv\")\n",
    "\n",
    "occ['ACS'] = occ['ACS'].astype(int)\n",
    "occ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_codes = occ[['ACS', 'Occupation Name']].to_dict(orient = 'records')\n",
    "\n",
    "ls_codes_occ = []\n",
    "for code in occ_codes:\n",
    "    ls_codes_occ.append(list(code.values()))\n",
    "    \n",
    "    occupations = {item[0]: item[1] for item in ls_codes_occ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occ'] = df['occ'].map(occupations)\n",
    "\n",
    "df['occ'] = df['occ'].fillna(value = 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Natural Language Processing using SpaCy\n",
    "\n",
    "_Occupation codes_ are generalizations of individuals' occupations. For example, an individual with OCC code 50 has an occupation label of _Marketing and sales managers_ right now. In our tweets we want to speak in the first-person so the tweet would say something like ___\"I'm a marketing and sales manager\"___. This requires a little bit of NLP. \n",
    "\n",
    "Enter, SpaCy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy      # already imported at the beginning of the notebook but uncomment if needed\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "___quick note___: visit [spacy's documentation](https://spacy.io/usage/models) to learn about loading a model. For this example we're using the english language model but they have more languages!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code was found [here in stackoverflow](https://stackoverflow.com/a/44764557)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on POS-tagging: https://spacy.io/api/annotation#section-pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma = []\n",
    "tags = []\n",
    "nnps = []\n",
    "\n",
    "# Because we're only looking to create a occupation label for those who actually have a job\n",
    "data = df[df['empstat'] == 'employed'].copy()\n",
    "\n",
    "ok_tags = ['JJ', 'JJR', 'JJS', 'NN','NNS', 'NNPS'] # adjectives and nouns\n",
    "\n",
    "\n",
    "# this might take a while if you have a long dataframe\n",
    "for doc in nlp.pipe(data['occ'].astype('unicode').values, batch_size = 50, n_threads=3):\n",
    "    if doc.is_parsed:\n",
    "        lemma.append([n.lemma_ for n in doc])   # all words lemmatized\n",
    "        tags.append([n.lemma_ for n in doc if n.tag_ in ok_tags])    # lemmatized words only if nouns or adjectives\n",
    "        nnps.append([n.lemma_ for n in doc if n.tag_ == 'NNPS'])     # proper nouns\n",
    "    else:\n",
    "        # To make sure the list lemma and tag are the same length as the series OCC\n",
    "        lemma.append(None)\n",
    "        tags.append(None)\n",
    "        nnps.append(None)\n",
    "        \n",
    "\n",
    "data['occ_lemma'] = lemma\n",
    "data['occ_tag'] = tags\n",
    "data['occ_nnps'] = nnps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~9 minutes for 173,342 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point `data['occ_lemma']` and `data['occ_tag']` are series of lists which cannot be saved in `.dta` files. We'll have to change them to `strings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['occ_tag'] = data['occ_tag'].apply(lambda x: ', '.join(map(str, x)))\n",
    "data['occ_lemma'] = data['occ_lemma'].apply(lambda x: ', '.join(map(str, x)))\n",
    "data['occ_nnps'] = data['occ_nnps'].apply(lambda x: ', '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### At this point we have a working semi-cleaned dataset and we could save it as a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = pd.merge(df,data,how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are hosting this on github we'll try to keep the size to <25mb so we'll drop some columns:\n",
    "1. year: it's 2016 ACS data so we don't need a variable for year... it's 2016.\n",
    "2. gqtype and gqtyped: group quarters type and type detailed are probably not going to be interesting enough to tweet about it\n",
    "3. hhwt and perwt: household weight and person weight could be interesting. Maybe something like \"there are about {person[perwt]} people like me in CA\". So you could keep it if that's something that interests you.\n",
    "4. statefips: it's california. \n",
    "5. homeland: only tells you wether your puma (public use microdata area) contains a person's homeland\n",
    "6. puma, migpuma1, pwpuma00: this is 2016's puma code, if you want to use these you could use it to have a very specific area where this person would be tweeting from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanchez\\AppData\\Local\\Continuum\\anaconda3\\envs\\allCalifornians\\lib\\site-packages\\pandas\\io\\stata.py:637: ValueLabelTypeMismatch: \n",
      "Stata value labels (pandas categories) must be strings. Column language contains\n",
      "non-string labels which will be converted to strings.  Please check that the\n",
      "Stata data file created has not lost information due to duplicate labels.\n",
      "\n",
      "  ValueLabelTypeMismatch)\n"
     ]
    }
   ],
   "source": [
    "# dropping these columns will get you just under 25mb\n",
    "working_df.drop(columns = ['year', 'gqtype', 'gqtyped', 'hhwt', 'statefip', 'homeland', 'puma', 'pwpuma00', 'migpuma1'], inplace = True)\n",
    "\n",
    "# remove unused categories in your series\n",
    "for col in df.columns:\n",
    "    if str(df[col]) == 'category':\n",
    "        df[col].cat.remove_unused_categories()\n",
    "\n",
    "# The original file obtained from IPUMS is in .dta format so we'll keep it that way\n",
    "# it also conserves categoricals, which is useful.\n",
    "with gzip.open(\"../data/processed/working-101718_dataset.dta.gz\", \"wb\") as file:\n",
    "    working_df.to_stata(file, write_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# To be continued tomorrow:\n",
    "create sentence fragments from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datanum</th>\n",
       "      <th>serial</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>city</th>\n",
       "      <th>gq</th>\n",
       "      <th>farm</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>ownershpd</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>mortgag2</th>\n",
       "      <th>...</th>\n",
       "      <th>pwstate2</th>\n",
       "      <th>tranwork</th>\n",
       "      <th>carpool</th>\n",
       "      <th>riders</th>\n",
       "      <th>trantime</th>\n",
       "      <th>departs</th>\n",
       "      <th>arrives</th>\n",
       "      <th>occ_lemma</th>\n",
       "      <th>occ_tag</th>\n",
       "      <th>occ_nnps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned free and clear</td>\n",
       "      <td>no, owned free and clear</td>\n",
       "      <td>n/a</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned free and clear</td>\n",
       "      <td>no, owned free and clear</td>\n",
       "      <td>n/a</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>california</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>22</td>\n",
       "      <td>1105</td>\n",
       "      <td>1124</td>\n",
       "      <td>retail, salesperson</td>\n",
       "      <td>salesperson</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>california</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>141</td>\n",
       "      <td>502</td>\n",
       "      <td>704</td>\n",
       "      <td>retail, salesperson</td>\n",
       "      <td>salesperson</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datanum  serial countyfips                                      city  \\\n",
       "0        1   67752     Tulare  not in identifiable city (or size group)   \n",
       "1        1   67752     Tulare  not in identifiable city (or size group)   \n",
       "2        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "3        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "4        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "\n",
       "                                 gq      farm                      ownershp  \\\n",
       "0  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "1  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "2  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "3  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "4  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "\n",
       "                     ownershpd                                       mortgage  \\\n",
       "0         owned free and clear                       no, owned free and clear   \n",
       "1         owned free and clear                       no, owned free and clear   \n",
       "2  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "3  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "4  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "\n",
       "  mortgag2    ...       pwstate2             tranwork       carpool  \\\n",
       "0      n/a    ...            n/a                  n/a           n/a   \n",
       "1      n/a    ...            n/a                  n/a           n/a   \n",
       "2       no    ...     california  auto, truck, or van  drives alone   \n",
       "3       no    ...     california  auto, truck, or van  drives alone   \n",
       "4       no    ...            n/a                  n/a           n/a   \n",
       "\n",
       "         riders  trantime  departs arrives            occ_lemma      occ_tag  \\\n",
       "0           n/a         0        0       0                                     \n",
       "1           n/a         0        0       0                                     \n",
       "2  drives alone        22     1105    1124  retail, salesperson  salesperson   \n",
       "3  drives alone       141      502     704  retail, salesperson  salesperson   \n",
       "4           n/a         0        0       0                                     \n",
       "\n",
       "   occ_nnps  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading from check-point\n",
    "with gzip.open(\"../data/processed/working-101718_dataset.dta.gz\", \"rb\") as datafile:\n",
    "    working_df = pd.read_stata(datafile)\n",
    "    \n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Because we will not be using every single one of these 130 columns we can start dropping some. <br>\n",
    "The following I'll choose based on what I want my twitterbot to tweet, you may choose to keep whatever variable you're interested in if you are going to be using this dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a list of variables to drop\n",
    "income_vars = [col for col in working_df.columns if \"inc\" in col]\n",
    "\n",
    "income_vars.remove(\"incwage\") # we want to keep these\n",
    "income_vars.remove(\"inctot\")\n",
    "\n",
    "working_df.drop(columns=income_vars, inplace = True)\n",
    "\n",
    "# Repeat the process for other groups of variables\n",
    "vet_vars = [col for col in working_df.columns if \"vet\" in col]\n",
    "\n",
    "vet_vars.remove(\"vetstat\")\n",
    "\n",
    "working_df.drop(columns=vet_vars, inplace = True)\n",
    "\n",
    "# randoms\n",
    "other_vars = ['lingisol','city','multgend','ind','bpld','uhrswork','yrnatur', 'citizen','yrimmig','availble', 'foodstmp','marrno', 'divinyr', 'widinyr','wkswork2','mortgage', 'degfield', 'rentmeal','gq', 'degfield2','ownershp', 'ownershpd', 'mortgag2', 'farmprod', 'acrehous', 'mortamt1', 'mortamt2', 'rentgrs', 'fridge', 'hotwater', 'bedrooms', 'phone', 'cinethh', 'cilaptop', 'cismrtphn', 'citablet', 'ciothcomp', 'cidatapln', 'fuelheat', 'nfams', 'nsubfam', 'ncouples', 'birthyr', 'raced', 'race', 'hispan', 'hispand', 'ancestr1', 'ancestr2', 'languaged', 'educ', 'gradeatt', 'schltype', 'degfieldd', 'degfield2d', 'empstatd', 'classwkr', 'classwkrd', 'migrate1d', 'movedin']\n",
    "\n",
    "working_df.drop(columns=other_vars, inplace = True)\n",
    "\n",
    "# cost\n",
    "cost_vars = [col for col in working_df.columns if 'cost' in col]\n",
    "\n",
    "working_df.drop(columns=cost_vars, inplace = True)\n",
    "\n",
    "# health insurance\n",
    "health_vars = [col for col in working_df.columns if 'hins' in col]\n",
    "\n",
    "working_df.drop(columns=health_vars, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "You can save this trimmed dataset and start working on building your sentences from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/processed/working-101818-cleaned_dataset.dta.gz\", \"wb\") as file:\n",
    "    working_df.to_stata(file, write_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing sentences\n",
    "\n",
    "Based on the variables left I put came up with 11 different categories.\n",
    "\n",
    "1. Demographics:\n",
    "  - countyfips, sex, age, marst, yrmarr,\n",
    "2. Household:\n",
    "  - farm, rent, vehicles, ssmc, multgen\n",
    "3. Work:\n",
    "  - empstat, labforce, occ, looking, pwstate2, occ_lemma, occ_tag, occ_nnps\n",
    "4. Origin\n",
    "  - bpl, ancestr1d, ancestr2d, yrsusa1\n",
    "5. Language\n",
    "  - language\n",
    "6. Health coverage:\n",
    "  - hcovany\n",
    "7. Education\n",
    "  - educd, gradeattd\n",
    "8. Money\n",
    "  - inctot, incwage, poverty\n",
    "9. Moving\n",
    "  - migrate1, migplac1\n",
    "10. Veteran\n",
    "  - vetstat\n",
    "11. Commute\n",
    "  - tranwork, carpool, riders, trantime, departs, arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these categories we can create 11 potential sentence fragments. Of course, not all observations will have all 11 fragments.\n",
    "\n",
    "Before moving to the code itself it's a good idea to map out the logic for each fragment in ___pseudo-code___:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Demographics\n",
    "\n",
    "`countyfips`, `age`, and `sex` are values we can expect from every observation so we can build a sentence from there. The other variables _could or could not_ have values depending on whether a person is married or not (`marst`).\n",
    "\n",
    "An example sentence:<br>\n",
    "```python\n",
    "sentence = \"I'm {age}, from {countyfips}\"\n",
    "if sex == 'male':\n",
    "    sentence += man emoji\n",
    "else:\n",
    "    sentence += woman emoji\n",
    "\n",
    "if age >= 18:\n",
    "    if marst == \"never married/single\":\n",
    "        sentence = sentence + \". I'm single\"\n",
    "    elif \"married\" in marst:\n",
    "        sentence += \"I got married in {yrmarr}\"\n",
    "    else:\n",
    "        sentence += first word of marst ## divorced, separated, or widowed.\n",
    "else:\n",
    "    pass\n",
    "```\n",
    "\n",
    "So you end up with either <br>\n",
    "_\"I'm 16 {emoji}, from San Diego county\"_ or <br>\n",
    "_\"I'm 34 {emoji}, from Alameda county. I got married in 2007.\"_ or <br>\n",
    "_\"I'm 40 {emoji}, from Los Angeles county. I'm divorced.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Household\n",
    "All variables in the Household category are _conditional_\n",
    "\n",
    "```python\n",
    "if farm == 'farm':\n",
    "    sentence = 'I live in a farm! {farmer emoji}'\n",
    "else:\n",
    "    sentence = \"\"\n",
    "\n",
    "if rent >= 0:\n",
    "    sentence += \"I pay {rent} in rent.\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if vehicles > \"1 available\":\n",
    "    sentence += \"I have a car available {car emoji}\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if ssmc != \"households without a same-sex married couple\":\n",
    "    sentence += \"{rainbow emoji}\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if multgen == \"2 generations\" | \"3+ generations\":\n",
    "    sentence += \"more than 1 generation lives in my home.\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "```\n",
    "\n",
    "In some cases you'll end up with a blank string for sentence but in others you may potentially end up with a 4 part sentence: <br>_\"I live in a farm! {farmer emoji}. I pay {rent} in rent. I have a car available {car emoji}. {rainbow}. More than 1 generation lives in my home.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Work\n",
    "The work sentence is a little more complicated. We used spacy to create `occ_lemma`, `occ_tag`, and `occ_nnps`. From which we can create a \"job title\" label but for the rest we can create other fragments.\n",
    "foodstmp, empstat, labforce, occ, uhrswork, looking, availble, pwstate2, occ_lemma, occ_tag, occ_nnps\n",
    "\n",
    "```python\n",
    "if empstat == 'unemployed':\n",
    "    sentence = \"I'm unemployed\"\n",
    "    if looking == 'yes, looked for work':\n",
    "        sentence += \", but I'm still looking for a job.\"\n",
    "    else:\n",
    "        sentence += \".\"\n",
    "elif empstat == 'employed':\n",
    "    sentence = \"I work as {job label from occ_lemma or occ_tag}\"\n",
    "    if pwstate2 != 'n/a' & pwstate2 != 'california':\n",
    "        sentence += \" in {pwstate2}.\"\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    sentence = \"\"\n",
    "    \n",
    "```\n",
    "\n",
    "So you end up with something like:<br>\n",
    "_\"I'm unemployed, but I'm still looking for a job.\"_ or <br>\n",
    "_\"I'm unemployed.\"_ or <br>\n",
    "_\"I work as a scientist in Canada.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Origin\n",
    "The origin sentence is a little more straight-forward.\n",
    "\n",
    "```python\n",
    "sentence = \"I was born in {bpl}.\"\n",
    "if ancestr1d != \"not classified\" | \"other\" | \"not reported\":\n",
    "    sentence += \"I am {ancestr1d}\"\n",
    "    if ancestr2d != \"not classified\" | \"other\" | \"not reported\":\n",
    "        sentence += \" and {ancestr2d}.\"\n",
    "    else:\n",
    "        sentence += \".\"\n",
    "else:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Language and health coverage\n",
    "These are simple straight-forward sentences:\n",
    "```python\n",
    "if language != \"other or not reported\":\n",
    "    sentence = \"I speak {language} at home.\"\n",
    "else:\n",
    "    sentence = \"\"\n",
    "    \n",
    "if hcovany == \"with health insurance coverage\":\n",
    "    sentence = \"I have health insurance.\"\n",
    "else:\n",
    "    sentence = \"I don't have health insurance.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Education\n",
    "```python\n",
    "if age < 18:\n",
    "    sentence = \"I am in {gradeattd}.\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
